{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "\n",
    "class PerturbationTool():\n",
    "    def __init__(self, seed=0, epsilon=0.03137254901, num_steps=20, step_size=0.00784313725):\n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "        self.step_size = step_size\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def random_noise(self, noise_shape=[10, 3, 32, 32]):\n",
    "        random_noise = torch.FloatTensor(*noise_shape).uniform_(-self.epsilon, self.epsilon).to(device)\n",
    "        return random_noise\n",
    "\n",
    "    def min_min_attack(self, images, labels, model, optimizer, criterion, random_noise=None, sample_wise=False):\n",
    "        if random_noise is None:\n",
    "            random_noise = torch.FloatTensor(*images.shape).uniform_(-self.epsilon, self.epsilon).to(device)\n",
    "            \n",
    "        perturb_img = Variable(images.data + random_noise, requires_grad=True)\n",
    "        perturb_img = Variable(torch.clamp(perturb_img, 0, 1), requires_grad=True).reshape([32,3,32,32])\n",
    "        perturb_img = perturb_img.cuda().detach()\n",
    "        perturb_img.requires_grad = True\n",
    "\n",
    "        eta = random_noise\n",
    "        for _ in range(self.num_steps):\n",
    "            opt = torch.optim.SGD([perturb_img], lr=1e-3)\n",
    "            opt.zero_grad()\n",
    "            model.zero_grad()\n",
    "            if isinstance(criterion, torch.nn.CrossEntropyLoss):\n",
    "                if hasattr(model, 'classify'):\n",
    "                    model.classify = True\n",
    "                logits = model(perturb_img)\n",
    "                logits = logits.view(-1, 1*10)\n",
    "                if len(labels)==1:\n",
    "                    labels = torch.tensor([lab for lab in labels for i in range(len(logits/10))]).cuda()\n",
    "                else:\n",
    "                    continue\n",
    "                loss = criterion(logits, labels)\n",
    "            else:\n",
    "                logits, loss = criterion(model, perturb_img, labels, optimizer)\n",
    "            perturb_img.retain_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            eta = self.step_size * perturb_img.grad.data.sign() * (-1)\n",
    "            perturb_img = Variable(perturb_img.data + eta, requires_grad=True)  # shape([32, 3, 32, 32])\n",
    "            images = images.repeat(32,1,1).resize(32,3,32,32)\n",
    "            eta = torch.clamp(perturb_img.data - images.data, -self.epsilon, self.epsilon)\n",
    "            perturb_img = Variable(images.data + eta, requires_grad=True)\n",
    "            perturb_img = Variable(torch.clamp(perturb_img, 0, 1), requires_grad=True)\n",
    "\n",
    "        return perturb_img, eta\n",
    "\n",
    "\n",
    "    def _patch_noise_extend_to_img(self, noise, image_size=[3, 32, 32], patch_location='center'):\n",
    "        c, h, w = image_size[0], image_size[1], image_size[2]\n",
    "        mask = np.zeros((c, h, w), np.float32)\n",
    "        x_len, y_len = noise.shape[1], noise.shape[1]\n",
    "\n",
    "        if patch_location == 'center' or (h == w == x_len == y_len):\n",
    "            x = h // 2\n",
    "            y = w // 2\n",
    "        elif patch_location == 'random':\n",
    "            x = np.random.randint(x_len // 2, w - x_len // 2)\n",
    "            y = np.random.randint(y_len // 2, h - y_len // 2)\n",
    "        else:\n",
    "            raise('Invalid patch location')\n",
    "\n",
    "        x1 = np.clip(x - x_len // 2, 0, h)\n",
    "        x2 = np.clip(x + x_len // 2, 0, h)\n",
    "        y1 = np.clip(y - y_len // 2, 0, w)\n",
    "        y2 = np.clip(y + y_len // 2, 0, w)\n",
    "        if type(noise) is np.ndarray:\n",
    "            pass\n",
    "        else:\n",
    "            mask[:, x1: x2, y1: y2] = noise.cpu().numpy()\n",
    "        return ((x1, x2, y1, y2), torch.from_numpy(mask).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.ResNet import ResNet18\n",
    "from util import AverageMeter\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "CLASS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def find_similar_img(target, k=50):\n",
    "    trainDataLoader = torch.utils.data.DataLoader(dataset=clean_train_dataset, batch_size=1)\n",
    "    processBar = tqdm(trainDataLoader, unit='step')\n",
    "    sims = {}\n",
    "    for index, (trainImgs, labels) in enumerate(processBar):\n",
    "        trainImgs = trainImgs.to(device)\n",
    "        cos_sim = torch.nn.functional.cosine_similarity(target.flatten(), trainImgs.flatten(), dim=0)\n",
    "        sims[index] = cos_sim\n",
    "    sims = sorted(sims.items(), key=lambda x: x[1], reverse=True)\n",
    "    # print(sims[:10])  # (9881, tensor(0.9158))\n",
    "    # print(sims[0][0])  # 9881\n",
    "    \n",
    "    sim_group = []\n",
    "    for i in range(k):\n",
    "        sim_group.append(sims[i][0])\n",
    "\n",
    "    return sim_group\n",
    "\n",
    "def linear_interpolation(target_img, sim_img_group, alpha=0.1):\n",
    "    ip_img = []\n",
    "    for img in sim_img_group:\n",
    "        interpolation = alpha * target_img + (1-alpha) * img\n",
    "        ip_img.append(interpolation)\n",
    "    return ip_img\n",
    "\n",
    "def generate_noise(base_model, criterion, optimizer, interpolation_imgs, intended_labels, MAX_ITERATION=10):\n",
    "    noise = torch.zeros([len(interpolation_imgs), 32, 32, 3]).to(device)\n",
    "    data_iter = iter(interpolation_imgs)\n",
    "    condition = True\n",
    "    train_idx = 0\n",
    "    # intended_labels = torch.nn.functional.one_hot(intended_labels, num_classes = len(CLASS))\n",
    "    intended_labels = torch.tensor([intended_labels,])\n",
    "\n",
    "    while condition:\n",
    "        base_model.train()\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "        for j in range(0, MAX_ITERATION):\n",
    "            try:\n",
    "                images = next(data_iter)\n",
    "            except:\n",
    "                train_idx = 0\n",
    "                data_iter = iter(clean_train_loader)\n",
    "                images = next(data_iter)\n",
    "            \n",
    "            for i, _ in enumerate(images):\n",
    "                images += noise[train_idx]\n",
    "                train_idx += 1 if train_idx !=49 else 0\n",
    "            images, intended_labels = images.cuda().reshape([1,3,32,32]), intended_labels.cuda()\n",
    "            base_model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            logits = base_model(images)\n",
    "            loss = criterion(logits, intended_labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(base_model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        idx = 0\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for i, images in tqdm(enumerate(interpolation_imgs), total=len(interpolation_imgs)):\n",
    "            batch_start_idx, batch_noise = idx, []\n",
    "            labels = intended_labels.clone()\n",
    "            for i, _ in enumerate(images):\n",
    "                batch_noise.append(noise[idx])\n",
    "                idx += 1 if idx !=49 else 0\n",
    "            batch_noise = torch.stack(batch_noise).cuda()\n",
    "            \n",
    "            base_model.eval()\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            perturb_img, eta = noise_generator.min_min_attack(images, labels, base_model, optimizer, criterion, \n",
    "                                                            random_noise=batch_noise)\n",
    "            \n",
    "            eta = eta.resize(32,32,32,3)\n",
    "            for i, delta in enumerate(eta):\n",
    "                noise[batch_start_idx+i] = delta.clone().detach().cpu()\n",
    "            \n",
    "        eval_idx, total, correct = 0, 0, 0\n",
    "        for i, (images, labels) in enumerate(clean_train_loader):\n",
    "            for i, _ in enumerate(images):\n",
    "                images[i] += noise[eval_idx]\n",
    "                eval_idx += 1 if eval_idx !=49 else 0\n",
    "            images, labels = images.cuda(), labels\n",
    "            with torch.no_grad():\n",
    "                logits = base_model(images)\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        acc = correct / total\n",
    "        print('Accuracy %.6f' % (acc*100))\n",
    "        if acc > 0.95:\n",
    "            condition=False  \n",
    "        return images, noise\n",
    "\n",
    "def create_poison_dataset(new_imgs):\n",
    "    poison_dataset = new_imgs\n",
    "    poison_dataset.data = poison_dataset.data.astype(np.float32)\n",
    "    for i in range(len(poison_dataset)):\n",
    "        poison_dataset.data[i] = np.clip(poison_dataset.data[i], a_min=0, a_max=255)\n",
    "    poison_dataset.data = poison_dataset.data.astype(np.uint8)\n",
    "    return poison_dataset\n",
    "\n",
    "def train_new_poisoned_model(poison_dataset, MAX_EPOCH=20, BATCH_SIZE=128):\n",
    "    model = ResNet18()\n",
    "    model = model.cuda()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1, weight_decay=0.0005, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0)\n",
    "\n",
    "    unlearnable_loader = DataLoader(poison_dataset, BATCH_SIZE=BATCH_SIZE,\n",
    "                                    shuffle=True, pin_memory=True,\n",
    "                                    drop_last=False, num_workers=12)\n",
    "    clean_train_dataset = datasets.CIFAR10(root, train=True, download=True, transform=train_transform)\n",
    "    clean_loader = DataLoader(clean_train_dataset, BATCH_SIZE=BATCH_SIZE,\n",
    "                                    shuffle=True, pin_memory=True,\n",
    "                                    drop_last=False, num_workers=12)\n",
    "    clean_test_dataset = datasets.CIFAR10(root, train=False, download=True, transform=test_transform)\n",
    "    clean_test_loader = DataLoader(dataset=clean_test_dataset, BATCH_SIZE=BATCH_SIZE,\n",
    "                                    shuffle=False, pin_memory=True,\n",
    "                                    drop_last=False, num_workers=12)\n",
    "    \n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        model.train()\n",
    "        acc_meter = AverageMeter()\n",
    "        loss_meter = AverageMeter()\n",
    "        pbar = tqdm([unlearnable_loader, clean_loader], total=len(unlearnable_loader, clean_loader))\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.cuda(), labels\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            acc = (predicted == labels).sum().item()/labels.size(0)\n",
    "            acc_meter.update(acc)\n",
    "            loss_meter.update(loss.item())\n",
    "            pbar.set_description(\"Acc %.4f Loss: %.4f\" % (acc_meter.avg*100, loss_meter.avg))\n",
    "        scheduler.step()\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        for i, (images, labels) in enumerate(clean_test_loader):\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            with torch.no_grad():\n",
    "                logits = model(images)\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        acc = correct / total\n",
    "        tqdm.write('Clean Accuracy %.4f\\n' % (acc*100))\n",
    "        # Test target class\n",
    "        target = torch.tensor(clean_test_dataset.data[8745]).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            # print(CLASS[int(predicted)])\n",
    "    return predicted\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    root = './datasets/'\n",
    "    BATCH_SIZE = 128\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    NUM_POISON = 50\n",
    "\n",
    "    train_transform = [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "    test_transform = [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    "    train_transform = transforms.Compose(train_transform)\n",
    "    test_transform = transforms.Compose(test_transform)\n",
    "\n",
    "    clean_train_dataset = datasets.CIFAR10(root, train=True, download=True, transform=train_transform)\n",
    "    clean_test_dataset = datasets.CIFAR10(root, train=False, download=True, transform=test_transform)\n",
    "\n",
    "    clean_train_loader = DataLoader(dataset=clean_train_dataset, batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False, pin_memory=True,\n",
    "                                    drop_last=False, num_workers=12)\n",
    "    clean_test_loader = DataLoader(dataset=clean_test_dataset, batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False, pin_memory=True,\n",
    "                                    drop_last=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor(clean_test_dataset.data[8745]).to(device)\n",
    "label = 5\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "base_model = ResNet18()\n",
    "base_model = base_model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=base_model.parameters(), lr=0.1, weight_decay=0.0005, momentum=0.9)\n",
    "\n",
    "noise_generator = PerturbationTool(epsilon=0.03137254901960784, num_steps=20, step_size=0.0031372549019607846)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:26<00:00, 1862.78step/s]\n"
     ]
    }
   ],
   "source": [
    "similar_imgs = find_similar_img(target, NUM_POISON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:17,  2.85it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for dimension 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [100]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m interpolation_imgs \u001b[38;5;241m=\u001b[39m linear_interpolation(target, similar_imgs, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m perturb_img, noise \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintended_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_ITERATION\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m poison_dataset \u001b[38;5;241m=\u001b[39m create_poison_dataset(perturb_img)\n",
      "Input \u001b[0;32mIn [99]\u001b[0m, in \u001b[0;36mgenerate_noise\u001b[0;34m(base_model, criterion, optimizer, interpolation_imgs, intended_labels, MAX_ITERATION)\u001b[0m\n\u001b[1;32m     93\u001b[0m     eta \u001b[38;5;241m=\u001b[39m eta\u001b[38;5;241m.\u001b[39mresize(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, delta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(eta):\n\u001b[0;32m---> 95\u001b[0m         noise[batch_start_idx\u001b[38;5;241m+\u001b[39mi] \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     97\u001b[0m eval_idx, total, correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clean_train_loader):\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for dimension 0 with size 50"
     ]
    }
   ],
   "source": [
    "interpolation_imgs = linear_interpolation(target, similar_imgs, alpha=0.5)\n",
    "perturb_img, noise = generate_noise(base_model, criterion, optimizer, interpolation_imgs, intended_labels=torch.tensor(3), MAX_ITERATION=10)\n",
    "poison_dataset = create_poison_dataset(perturb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def get_pairs_of_imgs(idx):\n",
    "    clean_img = clean_train_dataset.data[idx]\n",
    "    unlearnable_img = poison_dataset.data[idx]\n",
    "    clean_img = torchvision.transforms.functional.to_tensor(clean_img)\n",
    "    unlearnable_img = torchvision.transforms.functional.to_tensor(unlearnable_img)\n",
    "\n",
    "    x = noise[idx]\n",
    "    x_min = torch.min(x)\n",
    "    x_max = torch.max(x)\n",
    "    noise_norm = (x - x_min) / (x_max - x_min)\n",
    "    noise_norm = torch.clamp(noise_norm, 0, 1)\n",
    "    return [clean_img, noise_norm, unlearnable_img]\n",
    "    \n",
    "selected_idx = [random.randint(0, NUM_POISON) for _ in range(3)]\n",
    "img_grid = []\n",
    "for idx in selected_idx:\n",
    "    img_grid += get_pairs_of_imgs(idx)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(torch.stack(img_grid), nrow=3, pad_value=255))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = train_new_poisoned_model(poison_dataset, MAX_EPOCH=20, BATCH_SIZE=128)\n",
    "print('Target 8745[dog] is classified as type {}'.format(CLASS[int(predict)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4932ccbec8dcca49d9ef47811dcb7514042770e3fab3c95640310a655c241a7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
